title,arxiv_id,related_works,search_query,papers_used
"CoCoNUT: Structural Code Understanding does not
fall out of a tree",,"In recent years, the exploration of large language models (LLMs) for code understanding and generation has gained significant traction. A common theme among several studies is the emphasis on enhancing LLMs' comprehension of code execution, which is crucial for tasks such as code generation, repair, and completion. Liu et al. (2023) in ""Code Execution with Pre-trained Language Models"" highlight the limitations of pre-trained models that primarily focus on static code structures, proposing CodeExecutor, a model that incorporates code execution pre-training to improve semantic comprehension. Similarly, Ding et al. (2023) introduce TRACED, an execution-aware pre-training strategy that combines static code with execution traces to better capture dynamic code properties, thereby improving performance on tasks like clone retrieval and vulnerability detection. Both studies underscore the importance of integrating execution dynamics into model training to enhance code understanding capabilities.

Another line of research focuses on the explicit modeling of execution traces to improve LLMs' reasoning about code. Armengol-Estapé et al. (2025) propose Execution Tuning (E.T.), a training procedure that models real-world program execution traces, achieving notable accuracy improvements on benchmarks like CruxEval and MBPP. This approach aligns with the work of Ni et al. (2024), who introduce NExT, a method that uses execution traces and chain-of-thought rationales to teach LLMs to reason about runtime behavior, significantly improving program repair tasks. These studies collectively emphasize the potential of execution trace modeling to enhance the reasoning capabilities of LLMs, particularly in understanding the dynamic aspects of code execution.

In addition to execution trace modeling, there is a growing interest in developing tools for in-depth analysis of LLMs' code execution reasoning. Liu and Jabbarvand (2025) present ExeRScope, a toolset designed to analyze the impact of code properties on execution reasoning frameworks. This tool facilitates the generalization of findings across different datasets, addressing the need for comprehensive evaluation tools in the field. Such tools are crucial for advancing the understanding of LLMs' execution reasoning abilities and guiding the development of next-generation models.

Our work builds upon these foundational studies by specifically addressing the gap in LLMs' ability to appreciate the structural control flow of code, a critical aspect of human-like code reasoning. While existing models demonstrate impressive performance on benchmarks like HumanEval, our research reveals their limited capacity to trace execution paths, particularly for complex structures such as recursion, parallel processing, and object-oriented programming. By introducing the Benchmark CoCoNUT, we provide a novel dataset that challenges LLMs to navigate and understand advanced structural components of code. This work not only highlights the current limitations of LLMs in code reasoning but also offers a valuable resource for future research aimed at bridging this gap.",large language models code understanding execution tracing,"['Chenxiao Liu, Shuai Lu, Weizhu Chen, Daxin Jiang, Alexey Svyatkovskiy, Shengyu Fu, Neel Sundaresan, Nan Duan (2023). Code Execution with Pre-trained Language Models. arXiv:2305.05383v1. https://arxiv.org/abs/2305.05383v1', ""Jordi Armengol-Estapé, Quentin Carbonneaux, Tianjun Zhang, Aram H. Markosyan, Volker Seeker, Chris Cummins, Melanie Kambadur, Michael F. P. O'Boyle, Sida Wang, Gabriel Synnaeve, Hugh James Leather (2025). What I cannot execute, I do not understand: Training and Evaluating LLMs on Program Execution Traces. arXiv:2503.05703v1. https://arxiv.org/abs/2503.05703v1"", 'Yangruibo Ding, Ben Steenhoek, Kexin Pei, Gail Kaiser, Wei Le, Baishakhi Ray (2023). TRACED: Execution-aware Pre-training for Source Code. arXiv:2306.07487v1. https://arxiv.org/abs/2306.07487v1', 'Ansong Ni, Miltiadis Allamanis, Arman Cohan, Yinlin Deng, Kensen Shi, Charles Sutton, Pengcheng Yin (2024). NExT: Teaching Large Language Models to Reason about Code Execution. arXiv:2404.14662v1. https://arxiv.org/abs/2404.14662v1', 'Changshu Liu, Reyhaneh Jabbarvand (2025). A Tool for In-depth Analysis of Code Execution Reasoning of Large Language Models. arXiv:2501.18482v1. https://arxiv.org/abs/2501.18482v1']"
"Partially private, optimistic, distributed, and verifiable machine learning inference",,"In recent years, the intersection of privacy, verifiability, and machine learning (ML) has garnered significant attention, particularly in the context of distributed and federated learning environments. A notable contribution in this domain is the work by Riasi et al. (2024), which introduces vPIN, a privacy-preserving and verifiable convolutional neural network (CNN) inference scheme. This approach addresses the dual challenges of client data privacy and inference verifiability by employing partial homomorphic encryption and commit-and-prove succinct non-interactive argument of knowledge techniques. The authors demonstrate the efficiency of vPIN through various optimizations that reduce the proving circuit for homomorphic inference evaluation, achieving high efficiency in terms of proving time, verification time, and proof size. This work is particularly relevant to our research as it highlights the importance of verifiable inference in ML services, a theme that resonates with our focus on ensuring verifiable and tamper-proof inference in distributed ML settings (Riasi et al., 2024).

Another significant contribution in this field is the VerifBFL framework proposed by Bellachia et al. (2025), which leverages blockchain technology and cryptographic protocols to enhance the privacy and verifiability of federated learning (FL). VerifBFL integrates zero-knowledge Succinct Non-Interactive Argument of Knowledge (zk-SNARKs) and incrementally verifiable computation (IVC) to ensure the integrity and auditability of local training and aggregation processes. By verifying proofs on-chain, VerifBFL guarantees the trustworthiness of each participant's contributions, addressing vulnerabilities such as inference and model poisoning attacks. This work underscores the potential of zk-SNARKs in creating trustless and verifiable ML frameworks, aligning closely with our approach of using zk-SNARKs to enable partial privacy in distributed ML inference (Bellachia et al., 2025).

Both vPIN and VerifBFL illustrate the growing trend of integrating cryptographic techniques to enhance privacy and verifiability in ML applications. While vPIN focuses on client data privacy during inference, VerifBFL extends these principles to federated learning environments, ensuring the verifiability of both local training and aggregation. These works collectively emphasize the critical need for robust privacy-preserving mechanisms in ML, particularly in distributed settings where trust assumptions are minimal. Our research builds upon these foundational ideas by specifically addressing the privacy of model parameters during inference, a relatively underexplored area compared to input privacy.

In the context of these existing works, our research contributes a novel perspective by proposing a solution that allows model providers to selectively reveal model sections, thereby ensuring verifiable and tamper-proof inference across a customizable set of trusted and untrusted nodes. By focusing on the privacy of model parameters, our approach complements existing efforts that primarily address input privacy and inference verifiability. Our proof-of-concept implementation and performance evaluation further demonstrate the feasibility of our solution for models of varying sizes, highlighting its potential applications in ML edge computing and LoRA fine-tuned ML models. As we continue to explore optimizations for larger models, our work aims to bridge the gap between privacy and verifiability in distributed ML inference, fostering trust among all participants in the ML ecosystem.",machine learning privacy distributed inference zero-knowledge proofs,"['Arman Riasi, Jorge Guajardo, Thang Hoang (2024). Privacy-Preserving Verifiable Neural Network Inference Service. arXiv:2411.07468v2. https://arxiv.org/abs/2411.07468v2', 'Ahmed Ayoub Bellachia, Mouhamed Amine Bouchiha, Yacine Ghamri-Doudane, Mourad Rabah (2025). VerifBFL: Leveraging zk-SNARKs for A Verifiable Blockchained Federated Learning. arXiv:2501.04319v1. https://arxiv.org/abs/2501.04319v1']"
"SpikeDecoder: Realizing the GPT Architecture
with Spiking Neural Networks",,"The integration of spiking neural networks (SNNs) with Transformer architectures has garnered significant attention due to the potential for energy-efficient computation. Recent advancements have primarily focused on adapting the self-attention mechanism and Transformer-based architectures to SNNs, as seen in the work of Shi et al. (2024), who introduced the SpikingResformer. This model bridges ResNet and Vision Transformer architectures within SNNs, utilizing a novel Dual Spike Self-Attention mechanism to enhance performance and energy efficiency in computer vision tasks. Similarly, Wang et al. (2023) proposed AutoST, a training-free neural architecture search method for Spiking Transformers, which addresses the architectural gap between SNNs and their ANN counterparts by optimizing performance through a novel use of Floating-Point Operations as a performance metric.

In the realm of hardware optimization, Xu et al. (2024) explored the design of 3D spiking transformer hardware accelerators, highlighting the potential for significant energy and delay improvements through 3D integration techniques. This work underscores the importance of dedicated hardware support for spiking transformers, which is crucial for realizing their full potential in energy-constrained environments. Meanwhile, Yao et al. (2024) in their work on Spike-driven Transformer V2, emphasized the need for a meta-architecture that not only supports various vision tasks but also inspires the design of next-generation neuromorphic chips. Their approach focuses on achieving high performance while maintaining low power consumption, a theme echoed in their subsequent work on scaling spike-driven transformers with efficient spike firing approximation training (Yao et al., 2024).

The exploration of spatial-temporal attention mechanisms in spike-based transformers is another critical area of research. Lee et al. (2024) introduced the Spiking Transformer with Spatial-Temporal Attention (STAtten), which integrates both spatial and temporal information to improve feature representation and performance across static and neuromorphic datasets. This approach addresses the limitations of existing spike-based transformers that predominantly focus on spatial attention, thereby enhancing the overall efficacy of SNNs in processing complex data patterns.

In the context of these advancements, our work on SpikeDecoder represents a novel contribution to the field by extending the application of spiking transformers to natural language processing (NLP). Unlike previous efforts that have primarily focused on computer vision, our research investigates the potential of a fully spike-based low-power Transformer decoder-only model for NLP tasks. By analyzing the impact of replacing ANN components with spike-based alternatives and exploring spike-compatible normalization techniques, we aim to identify and mitigate performance bottlenecks. Our work not only demonstrates significant energy savings but also provides insights into the effective integration of SNNs with Transformer architectures, paving the way for future research in energy-efficient NLP models.",Transformer architecture energy efficiency spiking neural networks,"['Xinyu Shi, Zecheng Hao, Zhaofei Yu (2024). SpikingResformer: Bridging ResNet and Vision Transformer in Spiking Neural Networks. arXiv:2403.14302v2. https://arxiv.org/abs/2403.14302v2', 'Ziqing Wang, Qidong Zhao, Jinku Cui, Xu Liu, Dongkuan Xu (2023). AutoST: Training-free Neural Architecture Search for Spiking Transformers. arXiv:2307.00293v2. https://arxiv.org/abs/2307.00293v2', 'Boxun Xu, Junyoung Hwang, Pruek Vanna-iampikul, Sung Kyu Lim, Peng Li (2024). Spiking Transformer Hardware Accelerators in 3D Integration. arXiv:2411.07397v1. https://arxiv.org/abs/2411.07397v1', 'Donghyun Lee, Yuhang Li, Youngeun Kim, Shiting Xiao, Priyadarshini Panda (2024). Spiking Transformer with Spatial-Temporal Attention. arXiv:2409.19764v3. https://arxiv.org/abs/2409.19764v3', 'Man Yao, Jiakui Hu, Tianxiang Hu, Yifan Xu, Zhaokun Zhou, Yonghong Tian, Bo Xu, Guoqi Li (2024). Spike-driven Transformer V2: Meta Spiking Neural Network Architecture Inspiring the Design of Next-generation Neuromorphic Chips. arXiv:2404.03663v1. https://arxiv.org/abs/2404.03663v1', 'Man Yao, Xuerui Qiu, Tianxiang Hu, Jiakui Hu, Yuhong Chou, Keyu Tian, Jianxing Liao, Luziwei Leng, Bo Xu, Guoqi Li (2024). Scaling Spike-driven Transformer with Efficient Spike Firing Approximation Training. arXiv:2411.16061v1. https://arxiv.org/abs/2411.16061v1']"
"T2Vid: Translating Long Text into Multi-Image
is the Catalyst for Video-LLMs",2411.19951,"The exploration of Multimodal Large Language Models (MLLMs) for video understanding has gained significant traction in recent years, building upon the success of these models in the image domain. A key area of focus has been the challenge of extending the capabilities of MLLMs to comprehend long video sequences, as highlighted by Wei and Chen (2024) in their work on Visual Context Window Extension. They address the limitations of pretrained Large Multimodal Models (LMMs) in understanding lengthy video content by proposing an extension of the visual context window, which allows for improved performance on long video tasks without the need for retraining on extensive datasets. Their approach, which includes a progressive pooling inference strategy, demonstrates a reduction in memory usage while maintaining performance, offering a promising direction for efficient long video understanding (Wei & Chen, 2024).

Another significant theme in the literature is the use of MLLMs for data augmentation across various modalities, including image, text, and speech. Sapkota et al. (2025) provide a comprehensive survey of recent advancements in this area, highlighting the role of LLMs in enhancing dataset quality and diversity for deep learning applications. Their work identifies limitations in current data augmentation practices and suggests potential solutions to improve efficacy, thereby laying a foundation for future research in multimodal data augmentation (Sapkota et al., 2025). This survey underscores the importance of instruction diversity in training datasets, a concept that resonates with the challenges identified in our study regarding the low learning efficiency of fine-tuning approaches with video data.

In the realm of video-text understanding, Ma et al. (2024) introduce a novel evaluation task, retrieval from counterfactually augmented data (RCAD), to better assess the capabilities of video-text models. Their research reveals that existing models can be misled by counterfactually augmented data, indicating a gap between current model performance and human-level understanding. To address this, they propose the LLM-teacher approach, which leverages pretrained large language models to enhance action semantics learning, thereby improving model performance on the Feint6K dataset (Ma et al., 2024). This work highlights the importance of cross-frame reasoning and comprehensive video understanding, aligning with our focus on overcoming the limitations of zero-shot inference in MLLMs.

Our research builds upon these foundational studies by addressing the specific challenges of generalization and temporal understanding in zero-shot inference, as well as the inefficiencies in fine-tuning with video data. We introduce T2Vid, a method to synthesize video-like samples that enrich instruction diversity, thereby enhancing the training corpus. This approach not only achieves comparable performance with reduced sample sizes but also improves long video understanding without the need for long video samples. By integrating these insights, our work contributes to the ongoing discourse on optimizing MLLMs for video understanding and emphasizes the importance of high-quality data curation. We hope our findings will inspire further exploration and innovation in the application of MLLMs to video understanding tasks.",Multimodal Large Language Models video understanding zero-shot inference fine-tuning data augmentation,"['Hongchen Wei, Zhenzhong Chen (2024). Visual Context Window Extension: A New Perspective for Long Video Understanding. arXiv:2409.20018v2. https://arxiv.org/abs/2409.20018v2', 'Ranjan Sapkota, Shaina Raza, Maged Shoman, Achyut Paudel, Manoj Karkee (2025). Multimodal Large Language Models for Image, Text, and Speech Data Augmentation: A Survey. arXiv:2501.18648v2. https://arxiv.org/abs/2501.18648v2', 'Wufei Ma, Kai Li, Zhongshi Jiang, Moustafa Meshry, Qihao Liu, Huiyu Wang, Christian Häne, Alan Yuille (2024). Rethinking Video-Text Understanding: Retrieval from Counterfactually Augmented Data. arXiv:2407.13094v1. https://arxiv.org/abs/2407.13094v1']"
Reverse Thinking Makes LLMs Stronger Reasoners,2411.19865,"In recent years, the field of artificial intelligence has witnessed significant advancements in the development of large language models (LLMs) and their reasoning capabilities. A central theme in this domain is the exploration of human-like reasoning and the enhancement of LLMs to better emulate or complement human cognitive abilities. Maharshi Gor et al. (2024) introduce CAIMIRA, a framework that quantitatively assesses the problem-solving abilities of both humans and AI systems, revealing distinct proficiency patterns in reasoning skills. Their findings underscore the need for AI systems to tackle higher-order reasoning and nuanced linguistic interpretation, which aligns with the goals of our Reverse-Enhanced Thinking (REVTHINK) framework to improve reasoning performance through reverse thinking [1].

Another significant area of research focuses on the robustness and adaptability of LLMs in out-of-distribution reasoning tasks. Katherine M. Collins et al. (2022) propose a hybrid Parse-and-Solve model that augments LLMs with structured symbolic reasoning, demonstrating improved adaptation to novel problems. This approach highlights the potential of hybrid models to achieve more human-like reasoning, a concept that resonates with our REVTHINK framework's emphasis on structured forward-backward reasoning to enhance generalization capabilities [2]. Similarly, Wenlin Yao et al. (2024) introduce HDFlow, a framework that combines fast and slow thinking modes to tackle complex reasoning problems. Their dynamic workflows and hybrid thinking strategies offer insights into the benefits of integrating diverse reasoning approaches, which parallels our multi-task learning objectives in REVTHINK [5].

The integration of retrieval capabilities in reasoning models is another promising direction. Zhicheng Lee et al. (2025) present ReaRAG, a model that enhances factuality and reasoning robustness through iterative retrieval augmented generation. Their approach addresses the limitations of parametric knowledge in LLMs, emphasizing the importance of guided reasoning steps. This notion of iterative and guided reasoning is reflected in our REVTHINK framework, where backward reasoning serves as a consistency check to refine the reasoning trajectory [3]. Additionally, Dibyanayan Bandyopadhyay et al. (2025) provide a comprehensive survey of reasoning strategies in LLMs, highlighting the gap between language proficiency and reasoning abilities. Their work underscores the necessity of reasoning endowment in LLMs, a challenge that our REVTHINK framework seeks to address by enabling reverse thinking capabilities [4].

In summary, the existing body of research highlights various strategies to enhance the reasoning capabilities of LLMs, ranging from hybrid models and dynamic workflows to retrieval-augmented reasoning. Our REVTHINK framework contributes to this ongoing discourse by introducing a novel approach that leverages reverse thinking to improve reasoning performance and generalization. By augmenting datasets with structured forward-backward reasoning and employing multi-task learning objectives, REVTHINK not only enhances sample efficiency but also demonstrates strong generalization to out-of-distribution datasets, positioning it as a promising advancement in the quest for more human-like AI reasoning.","reverse thinking in AI, reasoning in large language models, data augmentation for reasoning tasks, multi-task learning in language models","['Maharshi Gor, Hal Daumé III, Tianyi Zhou, Jordan Boyd-Graber (2024). Do great minds think alike? Investigating Human-AI Complementarity in Question Answering with CAIMIRA. arXiv:2410.06524v1. https://arxiv.org/abs/2410.06524v1', 'Katherine M. Collins, Catherine Wong, Jiahai Feng, Megan Wei, Joshua B. Tenenbaum (2022). Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks. arXiv:2205.05718v1. https://arxiv.org/abs/2205.05718v1', 'Zhicheng Lee, Shulin Cao, Jinxin Liu, Jiajie Zhang, Weichuan Liu, Xiaoyin Che, Lei Hou, Juanzi Li (2025). ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation. arXiv:2503.21729v1. https://arxiv.org/abs/2503.21729v1', 'Dibyanayan Bandyopadhyay, Soham Bhattacharjee, Asif Ekbal (2025). Thinking Machines: A Survey of LLM based Reasoning Strategies. arXiv:2503.10814v1. https://arxiv.org/abs/2503.10814v1', 'Wenlin Yao, Haitao Mi, Dong Yu (2024). HDFlow: Enhancing LLM Complex Problem-Solving with Hybrid Thinking and Dynamic Workflows. arXiv:2409.17433v1. https://arxiv.org/abs/2409.17433v1']"
Money Burning Improves Mediated Communication,2411.19431,"In the realm of communication and information design, the role of mediation and commitment power has been extensively studied, particularly in the context of cheap talk and Bayesian persuasion. The work by Arieli, Geffner, and Tennenholtz (2023) on ""The Value of Mediation in Long Cheap Talk"" explores the benefits of introducing a trusted mediator in communication scenarios where the sender lacks commitment power. Their findings suggest that while a mediator may not directly enhance the payoffs for the sender or receiver in binary action settings, it can improve the outcomes for an external decision-maker whose utility is influenced by the receiver's actions. This highlights the nuanced role of mediation in enhancing communication outcomes, a theme that resonates with our exploration of money-burning tactics as a means to bolster commitment power in mediated communication.

Further expanding on the theme of mediation, Arieli, Geffner, and Tennenholtz (2022) in ""Mediated Cheap Talk Design"" investigate a setting with two informed senders and a receiver, where the senders lack commitment power. They introduce a mediator that aggregates information and recommends actions to the receiver, characterizing the set of implementable action distributions in equilibrium. Their work underscores the potential of mediation to optimize communication outcomes, even in the absence of sender commitment. This aligns with our research, which also seeks to enhance sender payoffs through strategic communication mechanisms, albeit through the novel approach of integrating money-burning tactics.

Our research builds on these foundational studies by introducing a model where the sender can design a communication mechanism that not only transmits messages but also incorporates money-burning as a commitment device. This approach diverges from traditional mediation by directly linking the sender's payoff to the act of burning money, thereby enhancing commitment power. The geometric characterization of the sender's maximum equilibrium payoff in our model provides a new perspective on robust Bayesian persuasion, offering insights into how commitment can be strategically leveraged in communication.

In contextualizing our work, it is important to note its applicability to Web 3.0 communities, where decentralized and trustless environments necessitate innovative commitment mechanisms. By demonstrating that money-burning can improve sender payoffs across a range of prior beliefs, our research contributes to the broader discourse on enhancing communication efficacy in digital ecosystems. This positions our study as a significant advancement in understanding the interplay between mediation, commitment, and communication in modern technological contexts.",mediated communication commitment power,"['Itai Arieli, Ivan Geffner, Moshe Tennenholtz (2023). The Value of Mediation in Long Cheap Talk. arXiv:2312.14793v2. https://arxiv.org/abs/2312.14793v2', 'Itai Arieli, Ivan Geffner, Moshe Tennenholtz (2022). Mediated Cheap Talk Design (with proofs). arXiv:2211.14670v2. https://arxiv.org/abs/2211.14670v2']"
"Condorcet-Consistent Choice
Among Three Candidates",2411.19857,"In the study of voting rules, particularly those that extend the Condorcet principle, various paradoxes and challenges have been identified and addressed in the literature. A significant body of work has focused on developing voting methods that are both Condorcet consistent and resistant to certain paradoxes. Holliday and Pacuit (2020) introduced the Split Cycle method, which is notable for its independence from clones and immunity to spoilers. This method addresses the ""spoiler effects"" and ""strong no-show paradoxes,"" which are critical issues in voting theory. Their work highlights the importance of developing voting rules that maintain consistency while mitigating the impact of additional candidates or voters, a theme that resonates with the challenges addressed in our research concerning the reinforcement and no-show paradoxes in Condorcet extensions.

Another relevant contribution to the field is by Peters (2017), who explored the manipulability of Condorcet-consistent voting rules through preference reversals. Peters' work corrects and extends previous findings by demonstrating that any Condorcet-consistent rule can be manipulated when there are at least four alternatives. This insight into the strategic vulnerabilities of voting rules complements our investigation into the reinforcement and no-show paradoxes, as both lines of inquiry seek to understand and mitigate the weaknesses inherent in Condorcet extensions.

Baharav, Constantinescu, and Wattenhofer (2025) examined the complexities of Condorcet winners in the context of weighted binary voting, particularly in relation to Ostrogorski's and Anscombe's paradoxes. Their work underscores the computational challenges in identifying Condorcet winners and provides efficient algorithms for certain voting conditions. The exploration of paradoxes in weighted voting systems parallels our focus on the reinforcement and no-show paradoxes, as both studies aim to identify conditions under which these paradoxes can be avoided or mitigated.

Our research builds upon these foundational studies by specifically addressing the reinforcement and no-show paradoxes in the context of three-candidate elections. We extend the understanding of Condorcet extensions by demonstrating that certain refinements of the maximin rule are immune to these paradoxes under specific conditions. By providing axiomatic characterizations of maximin and its refinements, such as Nanson’s rule and leximin, our work contributes to the ongoing discourse on the suitability and robustness of voting rules in small candidate elections. This research not only advances theoretical insights but also offers practical implications for designing voting systems that are both fair and resistant to strategic manipulation.",Condorcet extensions voting paradoxes,"['Wesley H. Holliday, Eric Pacuit (2020). Split Cycle: A New Condorcet Consistent Voting Method Independent of Clones and Immune to Spoilers. arXiv:2004.02350v10. https://arxiv.org/abs/2004.02350v10', ""Dominik Peters (2017). Condorcet's Principle and the Preference Reversal Paradox. arXiv:1707.08760v1. https://arxiv.org/abs/1707.08760v1"", 'Carmel Baharav, Andrei Constantinescu, Roger Wattenhofer (2025). Condorcet Winners and Anscombes Paradox Under Weighted Binary Voting. arXiv:2502.14639v1. https://arxiv.org/abs/2502.14639v1']"
Topological Approach for Data Assimilation,2411.18627,"In recent years, the integration of machine learning techniques with data assimilation has gained significant attention as researchers strive to improve the accuracy and efficiency of predictions in complex dynamical systems. A common theme among several studies is the use of ensemble-based methods to address challenges associated with model imperfections and high-dimensional systems. Luo (2019) explores the use of ensemble-based kernel learning to tackle simulator imperfections in data assimilation, highlighting the advantages of functional approximation through machine learning to enhance assimilation performance [1]. Similarly, Xiao et al. (2024) introduce the Latent Dynamics EnSF (LD-EnSF) method, which synergizes latent dynamics with ensemble score filters to accelerate data assimilation in sparse observation scenarios, demonstrating robustness and efficiency in high-dimensional nonlinear problems [6]. These studies underscore the potential of ensemble-based approaches to improve data assimilation by effectively handling model errors and sparse observations.

Another significant area of research focuses on the integration of deep learning models within data assimilation frameworks to address the computational challenges posed by high-dimensional systems. Cheng et al. (2024) present TorchDA, a Python package that seamlessly combines data assimilation with deep neural networks, offering flexible algorithm selection and enhanced performance in complex systems such as the Lorenz 63 and shallow water models [2]. This approach aligns with the growing interest in leveraging deep learning to improve the representation of state transitions and observation functions in data assimilation workflows. Li et al. (2024) propose the State-Observation Augmented Diffusion (SOAD) model, a generative approach that addresses the high nonlinearity in physical and observational models, offering theoretical advantages and improved performance over existing data-driven methods [4]. These contributions highlight the versatility and effectiveness of deep learning in enhancing data assimilation processes.

The challenge of assimilating data in chaotic dynamical systems is another critical area of exploration. McCabe and Brown (2021) introduce amortized assimilation, a framework for learning to assimilate from sequences of noisy observations without requiring ground truth data, thereby improving the effectiveness of data assimilation in chaotic systems [3]. Gottwald and Reich (2020) propose a method that combines machine learning algorithms with data assimilation to achieve increased forecast capabilities, demonstrating the potential of physics-agnostic approaches to enhance probabilistic forecasting and model closure in multi-scale systems [5]. These studies emphasize the importance of developing innovative assimilation techniques that can effectively handle the inherent uncertainty and complexity of chaotic systems.

In the context of these advancements, our research introduces a novel data assimilation algorithm grounded in topological data analysis, which leverages the differentiability of functions of persistence to optimize model coefficients without relying on noise information from measurements. By focusing on minimizing topological differences between measurements and forecast predictions, our approach offers a unique perspective on data assimilation, particularly in chaotic systems like the Lorenz system. This work builds upon the themes of ensemble-based learning, deep learning integration, and innovative assimilation techniques, contributing to the ongoing efforts to enhance the accuracy and reliability of data-driven models in complex dynamical systems.",data-driven models data assimilation machine learning,"['Xiaodong Luo (2019). Ensemble-based kernel learning for a class of data assimilation problems with imperfect forward simulators. arXiv:1901.10758v1. https://arxiv.org/abs/1901.10758v1', 'Sibo Cheng, Jinyang Min, Che Liu, Rossella Arcucci (2024). TorchDA: A Python package for performing data assimilation with deep learning forward and transformation functions. arXiv:2409.00244v1. https://arxiv.org/abs/2409.00244v1', 'Michael McCabe, Jed Brown (2021). Learning to Assimilate in Chaotic Dynamical Systems. arXiv:2111.01058v1. https://arxiv.org/abs/2111.01058v1', 'Zhuoyuan Li, Bin Dong, Pingwen Zhang (2024). State-observation augmented diffusion model for nonlinear assimilation with unknown dynamics. arXiv:2407.21314v2. https://arxiv.org/abs/2407.21314v2', 'Georg A. Gottwald, Sebastian Reich (2020). Supervised learning from noisy observations: Combining machine-learning techniques with data assimilation. arXiv:2007.07383v3. https://arxiv.org/abs/2007.07383v3', 'Pengpeng Xiao, Phillip Si, Peng Chen (2024). LD-EnSF: Synergizing Latent Dynamics with Ensemble Score Filters for Fast Data Assimilation with Sparse Observations. arXiv:2411.19305v1. https://arxiv.org/abs/2411.19305v1']"
"Timely and Energy-Efficient Multi-Step Update
Processing",2411.19854v1,"The study of systems involving multiple sequential processing steps has garnered significant attention in recent years, particularly in the context of optimizing performance metrics such as Age of Information (AoI) and power consumption. A notable contribution in this domain is the work by Vaze and Nair (2019), which investigates speed scaling in tandem server settings. Their research focuses on optimizing server speeds to balance power consumption and processing efficiency, considering both worst-case and stochastic scenarios. The authors propose algorithms that maintain constant competitiveness with optimal offline solutions, highlighting the importance of speed scaling in series server setups. This work is closely related to our research, as it addresses the power-performance trade-off in series systems, a key aspect of our AoI optimization problem. [Citation: Rahul Vaze, Jayakrishnan Nair (2019). Speed Scaling with Tandem Servers. arXiv:1907.04498v1.]

Parallel server systems have also been extensively studied, with a focus on routing policies and system stability. Moyal and Perry (2019) delve into the challenges of dispatching jobs in parallel-server systems, emphasizing the impact of routing errors on system performance. Their analysis of various dispatching policies, including the join the shortest workload (JSW) and join the shortest queue (JSQ) policies, provides insights into optimizing server utilization and minimizing sojourn times. This research is pertinent to our exploration of parallel setups, where multiple processors execute computation steps simultaneously. Understanding the stability and efficiency of routing policies in parallel systems informs our approach to optimizing AoI under power constraints. [Citation: Pascal Moyal, Ohad Perry (2019). Stability of Parallel Server Systems. arXiv:1904.10331v1.]

The Age of Information in queuing systems with heterogeneous servers is another critical area of study, as demonstrated by Bhati, Pillai, and Vaze (2021). Their work presents an optimal control problem aimed at minimizing average AoI across servers with varying capabilities. By deriving exact and approximate expressions for AoI, the authors provide valuable insights into server utilization and the benefits of adding more servers to the system. This research complements our investigation by offering a framework for understanding AoI dynamics in systems with diverse processing capabilities, which is essential for formulating effective optimization strategies in both parallel and series setups. [Citation: Anhad Bhati, Sibi Raj B. Pillai, Rahul Vaze (2021). On the Age of Information of a Queuing System with Heterogeneous Servers. arXiv:2109.05752v2.]

In summary, the existing literature provides a robust foundation for our research on optimizing AoI in systems requiring multiple sequential processing steps. By integrating insights from speed scaling, routing policies, and heterogeneous server dynamics, our work aims to address the age-power trade-off in both parallel and series server setups. Our contribution lies in identifying instances of wasted power and formulating an optimization problem to determine optimal service rates under a power budget, with a focus on systems requiring two computational steps. This research not only advances the understanding of AoI performance but also offers practical solutions for enhancing efficiency in real-world applications.",Age of Information performance analysis in parallel and series server setups with power optimization,"['Rahul Vaze, Jayakrishnan Nair (2019). Speed Scaling with Tandem Servers. arXiv:1907.04498v1. https://arxiv.org/abs/1907.04498v1', 'Pascal Moyal, Ohad Perry (2019). Stability of Parallel Server Systems. arXiv:1904.10331v1. https://arxiv.org/abs/1904.10331v1', 'Anhad Bhati, Sibi Raj B. Pillai, Rahul Vaze (2021). On the Age of Information of a Queuing System with Heterogeneous Servers. arXiv:2109.05752v2. https://arxiv.org/abs/2109.05752v2']"
A GEOMETRIC INVARIANT OF LINEAR RANK-METRIC CODES,2411.19087,"The study of rank-metric codes has been a vibrant area of research due to their applicability in various domains such as network coding, distributed storage, and cryptography. A significant body of work has focused on enhancing the resilience of these codes against specific types of errors, such as crisscross errors, which affect entire rows and columns in data matrices. Liu et al. (2018) explored the concept of locality in crisscross error correction, proposing a construction of cover-metric codes with locality that achieves a Singleton-like bound on the minimum cover distance. This work highlights the importance of designing codes that can efficiently recover lost symbols using only a few local symbols, a concept that resonates with the need for robust error correction in distributed storage systems [1].

In parallel, Martínez-Peñas (2017) addressed the challenge of reducing communication overheads in secure rank-metric coding schemes. By transforming coding schemes based on linear rank-metric codes, the study achieved optimal information rates while maintaining security and error correction capabilities. This work is particularly relevant for applications involving secure linear network coding and distributed storage systems, where minimizing communication overheads is crucial [2]. Additionally, Martínez-Peñas (2022) introduced the multi-cover metric to handle multilayer crisscross errors and erasures, further expanding the theoretical framework for error correction in complex data structures [3].

The concept of locality has also been extended to the rank and subspace metrics by Kadhe et al. (2017), who constructed array codes with locality constraints in the rank metric. Their work is motivated by the need for efficient data recovery from correlated failures in distributed storage systems. By deriving a Singleton-like upper bound on the minimum rank distance, they provided a construction that achieves this bound, thereby enhancing the reliability of storage systems against crisscross errors and erasures [4]. This aligns with the broader goal of developing robust coding schemes that can withstand various error patterns in practical applications.

Furthermore, Hörmann et al. (2022) focused on the sum-rank metric, proposing an error-erasure decoder for Linearized Reed-Solomon codes. This decoder is designed to correct full errors, row erasures, and column erasures, making it particularly useful for multishot network coding. The study underscores the versatility of sum-rank metric codes in error control, which is essential for maintaining data integrity in dynamic network environments [5].

In the context of these advancements, our research introduces a novel geometric invariant for linear rank-metric codes, inspired by the Schur product used in the Hamming metric. By examining the sequence of dimensions of Schur powers of the extended Hamming code associated with a linear code, we provide a new method to differentiate Gabidulin codes from random ones. This approach not only contributes to the theoretical understanding of rank-metric codes but also offers practical insights into their geometric properties, thereby enriching the existing literature on coding theory and its applications.",rank-metric codes geometric invariants network coding distributed storage crisscross error correction post-quantum cryptography,"['Hedongliang Liu, Lukas Holzbaur, Antonia Wachter-Zeh (2018). Locality in Crisscross Error Correction. arXiv:1806.07496v2. https://arxiv.org/abs/1806.07496v2', 'Umberto Martínez-Peñas (2017). Universal secure rank-metric coding schemes with optimal communication overheads. arXiv:1705.10592v2. https://arxiv.org/abs/1705.10592v2', 'Umberto Martínez-Peñas (2022). Multilayer crisscross error and erasure correction. arXiv:2203.07238v1. https://arxiv.org/abs/2203.07238v1', 'Swanand Kadhe, Salim El Rouayheb, Iwan Duursma, Alex Sprintson (2017). Codes with Locality in the Rank and Subspace Metrics. arXiv:1707.05944v3. https://arxiv.org/abs/1707.05944v3', 'Felicitas Hörmann, Hannes Bartz, Sven Puchinger (2022). Error-Erasure Decoding of Linearized Reed-Solomon Codes in the Sum-Rank Metric. arXiv:2202.06758v2. https://arxiv.org/abs/2202.06758v2']"
